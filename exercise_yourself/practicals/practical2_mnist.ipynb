{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries imported\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import dlc_practical_prologue as prologue\n",
    "import numpy as np\n",
    "\n",
    "print('libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n",
      "train_input torch.Size([1000, 784]) train_target torch.Size([1000])\n",
      "test_input torch.Size([1000, 784]) test_target torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = prologue.load_data()\n",
    "\n",
    "print('train_input', train_input.size(), 'train_target', train_target.size())\n",
    "print('test_input', test_input.size(), 'test_target', test_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_mnist_tensor(x, title: str):\n",
    "    n = int(np.sqrt(x.shape[1])) \n",
    "    plt.title(title)\n",
    "    plt.imshow(x.numpy().reshape(n, n), cmap=\"copper\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first algorithm implemented is the **1-Nearest Neighbours** to compute the distances between the training set and the testing set and set the label as according to the minimum of the **L2 Norm** distances: $argmin \\sum_n min_k ||y_i - x_n||^2 $ for each testing point $y_i, i = \\{1, ..., len(y)\\}$. \n",
    "\n",
    "In our case, we only have one neighbour so $k = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for L2 Norm 1-Nearest-Neighbour is: 17.2%\n"
     ]
    }
   ],
   "source": [
    "def error_rate(model_target, test_target):\n",
    "    return torch.sum(model_target != test_target).item() / len(test_target)\n",
    "\n",
    "\n",
    "def nearest_classification(x_train, x_label, y_test):\n",
    "    final_output = []\n",
    "    for y in y_test:\n",
    "        squared_distances = torch.sum(torch.pow(torch.sub(y, x_train), 2), 1).sqrt()\n",
    "        indices = torch.argmin(squared_distances)\n",
    "        output = x_label[indices]\n",
    "        final_output.append(output)\n",
    "    return torch.tensor(final_output)\n",
    "\n",
    "l2_nn_output = nearest_classification(train_input, train_target, test_input)\n",
    "print('Error rate for L2 Norm 1-Nearest-Neighbour is: {}%'.format(error_rate(l2_nn_output, test_target) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another version of the *Nearest Neighbour* algorithm however implemented a bit differently by taking two for loops. It takes $20x$ longer to execute however it gives a lower error rate (might be an implementation fault)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error - For Loop Element by Element Method: 0.1%\n"
     ]
    }
   ],
   "source": [
    "def nearest_classification_2(x_train, x_label, y_test):\n",
    "    final_output = []\n",
    "    for i in range(len(y_test)):\n",
    "        distance = [torch.sum(torch.pow(torch.sub(y_test[i], x_train[j]), 2)).sqrt() for j in range(len(x_train))]\n",
    "        test_predicted = x_label[np.argmin(distance)]\n",
    "        final_output.append(test_predicted)\n",
    "    return np.asarray(final_output)\n",
    "\n",
    "output2 = nearest_classification_2(train_input, train_target, test_input)\n",
    "print('Error - For Loop Element by Element Method: {}%'.format((float(np.sum(output2 != test_target)) / len(output2)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same distances and errors as the previous example will be performed however with the introduction of *mean*, a 1d float tensor of dimension $d$ (our train vectors are $n \\times d$), and *proj*, a 2d float tensor of dimension $c \\times d$.\n",
    "\n",
    "*mean* $\\rArr$ generated as a tensor filled with the constant float value $\\mu$, a parameter decided by the user.\n",
    "\n",
    "*proj* $\\rArr$ generated as a float tensor with uniformly distributed values from a custom interval $[r_1, r_2]$ .\n",
    "\n",
    "Both our training and testing sets of data will be subtracted with the *mean* vector, and a matrix multiplication will happen with the *proj* matrix, in order to compare the effect it will have on the error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for L2 Norm 1-Nearest-Neighbour after Mean Subtraction is: 18.2%\n",
      "Error rate for L2 Norm 1-Nearest-Neighbour after Projection Multiplication is: 52.400000000000006%\n"
     ]
    }
   ],
   "source": [
    "def compute_nb_errors(train_input, train_target, test_input, test_target, mean = None, proj = None): \n",
    "    if mean != None:\n",
    "        mean_tensor = torch.full((1, train_input.shape[1]), mean)\n",
    "        \n",
    "        test_input = torch.sub(test_input, mean_tensor)\n",
    "        train_input = torch.sub(train_input, mean_tensor)\n",
    "        \n",
    "        ## Change the negative values back to 0 using reLU\n",
    "        test_input = torch.nn.functional.relu(test_input)\n",
    "        train_input = torch.nn.functional.relu(train_input)\n",
    "        \n",
    "        output1 = nearest_classification(train_input, train_target, test_input)\n",
    "        error1 = error_rate(output1, test_target)\n",
    "    \n",
    "    if proj != None:\n",
    "        ## Torch Matrix Multiplication\n",
    "        test_input = torch.mm(test_input, proj)\n",
    "        train_input = torch.mm(train_input, proj)\n",
    "        \n",
    "        output2 = nearest_classification(train_input, train_target, test_input)\n",
    "        error2 = error_rate(output2, test_target)\n",
    "    \n",
    "    return error1, error2 \n",
    "\n",
    "\n",
    "mean = 25\n",
    "c = 126 ## size of the dimension of the proj matrix (d x c)\n",
    "r1 = 1.5\n",
    "r2 = 5\n",
    "proj_example = torch.FloatTensor(train_input.shape[1], c).uniform_(r1, r2)\n",
    "\n",
    "\n",
    "second_output, third_output = compute_nb_errors(train_input, train_target, test_input, test_target, mean = mean, proj = proj_example)\n",
    "\n",
    "print('Error rate for L2 Norm 1-Nearest-Neighbour after Mean Subtraction is: {}%'.format(second_output * 100))\n",
    "print('Error rate for L2 Norm 1-Nearest-Neighbour after Projection Multiplication is: {}%'.format(third_output * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other technique we will apply to our dataset is the *Principal Component Analysis* used for dimension reduction in order to increase the interpretability. Below is an implemented version of PCA by taking advantage of its relationship with *Singular Value Decomposition* such as:\n",
    "\n",
    "$A = U \\Sigma V^T$ for any matrix A. Where we know that the right singular vector $V$ is the **eigenvector** of the covariance matrix while the **eigenvalues** are hidden in the singular values $\\sigma$ of the diagonal matrix $\\Sigma$, two arguments that we require in order to perform PCA and get the principal components based on maximized variance.\n",
    "\n",
    "Using *PyTorch*, the SVD of the matrix can be found using **torch.linalg.svd(x)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def PCA_with_SVD(x, k):\n",
    "    ## A) Compute the mean and center the data\n",
    "    mu = torch.mean(x, 0, True) ## 1D Vector of Mean (dimension D, number of columns)\n",
    "    data_for_pca = torch.sub(x, mu)\n",
    "    \n",
    "    ## Singular Value Decomposition - Eigenvector is the transpose of the right singular vector (v_t)\n",
    "    u, s, v_t = torch.linalg.svd(data_for_pca)\n",
    "    pca_basis = v_t.t()[:, :k]\n",
    "    return mu, pca_basis\n",
    "\n",
    "number_of_components = train_input.shape[1] ## hardcoded to full components at the moment (dimension d)\n",
    "mean, eigvectors = PCA_with_SVD(train_input, number_of_components)\n",
    "\n",
    "# If Used Data is Tensor\n",
    "display_mnist_tensor(mean, 'Mean of All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for L2 Norm 1-Nearest-Neighbour after PCA is: 87.4%\n"
     ]
    }
   ],
   "source": [
    "## Projections of original observation onto new vector form\n",
    "z = torch.mm(train_input, eigvectors)\n",
    "l2_nn_output_after_pca = nearest_classification(z, train_target, test_input)\n",
    "print('Error rate for L2 Norm 1-Nearest-Neighbour after PCA is: {}%'.format(error_rate(l2_nn_output_after_pca, test_target) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST vs CIFAR\n",
    "\n",
    "The first observable difference regarding the performance of the algorithms between the two different datasets (**CIFAR-10** and **MNIST**) is the lower accuracy levels of *1-NN* when the **CIFAR-10** dataset is concerned. This is simply understandable from the fact that the images contained in this dataset are of a more complex structure on a pixel level. Consequently, the fact that two images who have a similar structure and mean of all pixels between them (on a block level) can easily be part of different classes of classification (one dog and one cat), leads to a higher level of the above mentioned error.\n",
    "\n",
    "On the contrary, in **MNIST**, structures and values of pixels (except the flat areas that make up the background) are usually a good indicator of what the number on the image is (the labels $0-9$), therefore the *1-NN* performs better automatically.\n",
    "\n",
    "Regarding the *Error Estimation* task of this practical, I can say that the subtraction of the mean and the projection of the data doesn't have a distinct effect on the accuracy overall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6290ab70aa2c9e6859d722745d4fdeafb895ca1190e93c7ac9c8d926153eb965"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
