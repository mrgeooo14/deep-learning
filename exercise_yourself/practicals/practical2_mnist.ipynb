{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries imported\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import dlc_practical_prologue as prologue\n",
    "import numpy as np\n",
    "\n",
    "print('libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n",
      "train_input torch.Size([1000, 784]) train_target torch.Size([1000])\n",
      "test_input torch.Size([1000, 784]) test_target torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = prologue.load_data()\n",
    "\n",
    "print('train_input', train_input.size(), 'train_target', train_target.size())\n",
    "print('test_input', test_input.size(), 'test_target', test_target.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first algorithm implemented is the **1-Nearest Neighbours** to compute the distances between the training set and the testing set and set the label as according to the minimum of the **L2 Norm** distances: $argmin \\sum_n min_k ||y_i - x_n||^2 $ for each testing point $y_i, i = \\{1, ..., len(y)\\}$. \n",
    "\n",
    "In our case, we only have one neighbour so $k = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for L2 Norm 1-Nearest-Neighbour is: 17.2%\n"
     ]
    }
   ],
   "source": [
    "def error_rate(model_target, test_target):\n",
    "    return torch.sum(model_target != test_target).item() / len(test_target)\n",
    "\n",
    "\n",
    "def nearest_classification(x_train, x_label, y_test):\n",
    "    final_output = []\n",
    "    for y in y_test:\n",
    "        squared_distances = torch.sum(torch.pow(torch.sub(y, x_train), 2), 1).sqrt()\n",
    "        indices = torch.argmin(squared_distances)\n",
    "        output = x_label[indices]\n",
    "        final_output.append(output)\n",
    "    return torch.tensor(final_output)\n",
    "\n",
    "l2_nn_output = nearest_classification(train_input, train_target, test_input)\n",
    "print('Error rate for L2 Norm 1-Nearest-Neighbour is: {}%'.format(error_rate(l2_nn_output, test_target) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another version of the *Nearest Neighbour* algorithm however implemented a bit differently by taking two for loops. It takes $20x$ longer to execute however it gives a lower error rate (might be an implementation fault)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error - Old Numpy Method: 0.1%\n"
     ]
    }
   ],
   "source": [
    "def nearest_classification_2(x_train, x_label, y_test):\n",
    "    final_output = []\n",
    "    for i in range(len(y_test)):\n",
    "        distance = [torch.sum(torch.pow(torch.sub(y_test[i], x_train[j]), 2)).sqrt() for j in range(len(x_train))]\n",
    "        test_predicted = x_label[np.argmin(distance)]\n",
    "        final_output.append(test_predicted)\n",
    "    return np.asarray(final_output)\n",
    "\n",
    "output2 = nearest_classification_2(train_input, train_target, test_input)\n",
    "print('Error - Old Numpy Method: {}%'.format((float(np.sum(output2 != test_target)) / len(output2)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same distances and errors as the previous example will be performed however with the introduction of *mean*, a 1d float tensor of dimension $d$ (our train vectors are $n \\times d$), and *proj*, a 2d float tensor of dimension $c \\times d$.\n",
    "\n",
    "*mean* $\\rArr$ generated as a tensor filled with the constant float value $\\mu$, a parameter decided by the user.\n",
    "\n",
    "*proj* $\\rArr$ generated as a float tensor with uniformly distributed values from a custom interval $[r_1, r_2]$ .\n",
    "\n",
    "Both our training and testing sets of data will be subtracted with the *mean* vector, and a matrix multiplication will happen with the *proj* matrix, in order to compare the effect it will have on the error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for L2 Norm 1-Nearest-Neighbour after Mean Subtraction is: 18.2%\n",
      "Error rate for L2 Norm 1-Nearest-Neighbour after Projection Multiplication is: 50.7%\n"
     ]
    }
   ],
   "source": [
    "def compute_nb_errors(train_input, train_target, test_input, test_target, mean = None, proj = None): \n",
    "    if mean != None:\n",
    "        mean_tensor = torch.full((1, train_input.shape[1]), mean)\n",
    "        \n",
    "        test_input = torch.sub(test_input, mean_tensor)\n",
    "        train_input = torch.sub(train_input, mean_tensor)\n",
    "        \n",
    "        ## Change the negative values back to 0 using reLU\n",
    "        test_input = torch.nn.functional.relu(test_input)\n",
    "        train_input = torch.nn.functional.relu(train_input)\n",
    "        \n",
    "        output1 = nearest_classification(train_input, train_target, test_input)\n",
    "        error1 = error_rate(output1, test_target)\n",
    "    \n",
    "    if proj != None:\n",
    "        ## Torch Matrix Multiplication\n",
    "        test_input = torch.mm(test_input, proj)\n",
    "        train_input = torch.mm(train_input, proj)\n",
    "        \n",
    "        output2 = nearest_classification(train_input, train_target, test_input)\n",
    "        error2 = error_rate(output2, test_target)\n",
    "    \n",
    "    return error1, error2 \n",
    "\n",
    "\n",
    "mean = 25\n",
    "c = 126 ## size of the dimension of the proj matrix (d x c)\n",
    "r1 = 1.5\n",
    "r2 = 5\n",
    "proj_example = torch.FloatTensor(train_input.shape[1], c).uniform_(r1, r2)\n",
    "\n",
    "\n",
    "second_output, third_output = compute_nb_errors(train_input, train_target, test_input, test_target, mean = mean, proj = proj_example)\n",
    "\n",
    "print('Error rate for L2 Norm 1-Nearest-Neighbour after Mean Subtraction is: {}%'.format(second_output * 100))\n",
    "print('Error rate for L2 Norm 1-Nearest-Neighbour after Projection Multiplication is: {}%'.format(third_output * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6290ab70aa2c9e6859d722745d4fdeafb895ca1190e93c7ac9c8d926153eb965"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
